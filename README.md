# ğŸ‡µğŸ‡¹ AlbertinaLLM  
Modelos e ferramentas de InteligÃªncia Artificial afinadas para o **PortuguÃªs Europeu** (pt-PT)

---

## ğŸ¯ Objectivos do Projecto

AlbertinaLLM Ã© uma LLM cuidadosamente construÃ­da com o propÃ³sito de:

- Suporte nativo e exclusivo para **PortuguÃªs Europeu (pt-PT)**  
- Capacidade bilingue limitada a **PortuguÃªs (pt-PT)** e **InglÃªs (EN)**
- EliminaÃ§Ã£o total de conteÃºdos em **PortuguÃªs do Brasil (pt-BR)**
- GeraÃ§Ã£o de instruÃ§Ãµes, respostas e cÃ³digo com clareza, utilidade e rigor linguÃ­stico
- AplicaÃ§Ã£o prÃ¡tica em tarefas como:
  - TraduÃ§Ã£o pt-EN
  - CompreensÃ£o de instruÃ§Ãµes
  - GeraÃ§Ã£o de SQL e cÃ³digo
  - Parsing inteligente de documentos (ex: faturas, PDFs)
  - Suporte offline com modelos locais (quantizados)

---

## ğŸ“œ Regras do Projecto

### âœ… Permitido

- LÃ­nguas suportadas: **PortuguÃªs Europeu** e **InglÃªs**
- Datasets curados manualmente ou validados automaticamente com assistente pt-PT
- Dados em formato **Parquet** para maximizar performance de I/O e treino
- Datasets de cÃ³digo, desde que:
  - Comentados em pt-PT ou inglÃªs formal (EN-GB)
  - Com boas prÃ¡ticas modernas
  - Limpos de exemplos obsoletos

### âŒ Proibido

- Qualquer dataset em **portuguÃªs do Brasil**
- ConteÃºdo com vocabulÃ¡rio, expressÃµes, instruÃ§Ãµes ou sintaxe tÃ­picas de pt-BR
- Datasets nÃ£o curados ou traduzidos automaticamente sem verificaÃ§Ã£o

---

## ğŸ“¦ Formato e OrganizaÃ§Ã£o dos Dados

- Todos os datasets sÃ£o convertidos para **`.parquet`**  
- A estrutura dos datasets segue o formato:
  - `instruction` â€“ a tarefa ou comando
  - `input` â€“ conteÃºdo adicional (opcional)
  - `output` â€“ resposta esperada
- Dados sÃ£o armazenados em diretÃ³rios como:
  - `/datasets/alpaca_ptpt_clean.parquet`
  - `/datasets/codigo/`
  - `/datasets/curados_manual/`

---

## âš™ï¸ Estado do Projecto

- [x] TraduÃ§Ã£o completa do dataset **Alpaca cleaned** (validaÃ§Ã£o manual)
- [x] TraduÃ§Ã£o em curso do dataset **GPT-4 Self Instruct DE â†’ pt-PT**
- [ ] IntegraÃ§Ã£o de capacidade de geraÃ§Ã£o SQL
- [ ] QuantizaÃ§Ã£o para execuÃ§Ã£o local (GGUF int3 / int4)
- [ ] CriaÃ§Ã£o de tokenizer prÃ³prio para portuguÃªs europeu

---

## ğŸ“š Tecnologias Utilizadas

- Python (Pandas, PyArrow, TQDM)
- OpenLLM / Transformers
- FastAPI (para UI auxiliar de conversÃ£o e treino)
- QuantizaÃ§Ã£o com `llm.cpp`, `gguf`, `optimum`, ou `mlc-llm`
- Ferramentas de traduÃ§Ã£o assistida: Yandex API, LibreTranslate local, pÃ³s-edited

---

## ğŸ¤ ContribuiÃ§Ãµes

Este Ã© um projecto **curado manualmente** com muito cuidado e atenÃ§Ã£o Ã  variante europeia da lÃ­ngua portuguesa.  
Se queres contribuir:

- Evita conteÃºdos em pt-BR
- Segue o padrÃ£o pt-PT
- Garante que o conteÃºdo seja realmente **Ãºtil e educativo**
- Pull requests com datasets devem ser justificados e acompanhados de amostra visÃ­vel

---

## ğŸ§  Autor e LicenÃ§a

**Autor**: Helder Lopes  
**LicenÃ§a**: MIT (excepto datasets, sujeitos Ã s suas prÃ³prias licenÃ§as)

âš ï¸ **Os datasets completos usados para treinar a AlbertinaLLM sÃ£o privados.**  
Apenas amostras representativas sÃ£o incluÃ­das para demonstraÃ§Ã£o da estrutura.


---

**AlbertinaLLM** â€” porque o PortuguÃªs Europeu tambÃ©m merece um LLM de excelÃªncia ğŸ‡µğŸ‡¹
